# Architecture de l'Application MLOps - Recommandation de Films

## Vue d'ensemble

Cette application est un syst√®me complet de recommandation de films utilisant les pratiques MLOps. Elle combine plusieurs technologies pour cr√©er un pipeline automatis√© d'entra√Ænement, de d√©ploiement et de monitoring de mod√®les de machine learning.

---

## üöÄ Flux de D√©marrage (Ordre d'Ex√©cution)

### 1. **Initialisation Docker** (`docker-compose.yml`)

Lorsque vous ex√©cutez `docker compose up`, les services d√©marrent dans cet ordre :

#### **√âtape 1.1 : Base de donn√©es PostgreSQL** (`db`)
- **Image** : `postgres:16-alpine`
- **R√¥le** : Stocke toutes les donn√©es (films, utilisateurs, √©valuations, tags)
- **Healthcheck** : V√©rifie que PostgreSQL est pr√™t avec `pg_isready`
- **Volumes** : 
  - `pg_data` : Donn√©es persistantes
  - `./src/data/sql` : Scripts SQL mont√©s

#### **√âtape 1.2 : Initialisation de la base** (`init_db`)
- **Script** : [`src/data/sql/init_init_db.sh`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/init_init_db.sh)
- **D√©pendances** : Attend que `db` soit healthy
- **Actions** :
  1. Cr√©e l'utilisateur et la base `airflow` pour Apache Airflow
  2. Accorde les permissions n√©cessaires
  3. Ex√©cute [`create_table.sql`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/create_table.sql) pour cr√©er les tables :
     - `users`, `movies`, `ratings`, `tags`, `genres`
     - `movie_genres`, `movie_tags`, `links`
     - `genome_tags`, `genome_scores`

#### **√âtape 1.3 : Import des donn√©es** (`import_data`)
- **Script** : [`docker/import_data/init_import_data.sh`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/docker/import_data/init_import_data.sh)
- **D√©pendances** : Attend `db` et `init_db`
- **Processus** :
  1. V√©rifie si la base est d√©j√† remplie avec [`check_db.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/check_db.py)
  2. Si vide, lance [`import_data.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/import_data.py) qui :
     - Lit les fichiers CSV du dataset MovieLens 20M
     - Importe ~20 millions d'√©valuations par chunks (50 000 lignes)
     - Importe films, utilisateurs, tags, genres, etc.
     - Prend environ 25 minutes

#### **√âtape 1.4 : MinIO** (`minio`)
- **R√¥le** : Stockage S3-compatible pour les artefacts MLflow et DVC
- **Ports** : 9000 (API), 9001 (Console web)
- **Healthcheck** : V√©rifie l'endpoint `/minio/health/ready`

#### **√âtape 1.5 : MLflow** (`mlflow`)
- **D√©pendances** : Attend que MinIO soit healthy
- **R√¥le** : Tracking des exp√©riences ML, gestion des mod√®les
- **Configuration** :
  - Backend store : SQLite local (`/mlflow`)
  - Artifact store : MinIO (S3)
- **Port** : 5000

#### **√âtape 1.6 : API FastAPI** (`api`)
- **D√©pendances** : Attend `db` et `mlflow`
- **R√¥le** : API REST pour les pr√©dictions, l'entra√Ænement et le monitoring
- **Port** : 8080 (mapp√© sur 8000 interne)

#### **√âtape 1.7 : Services de monitoring**
- **Prometheus** : Collecte les m√©triques (port 9090)
- **Grafana** : Visualisation des m√©triques (port 3001)

#### **√âtape 1.8 : Interface utilisateur**
- **Streamlit** : Interface web pour tester les recommandations (port 8501)

#### **√âtape 1.9 : Orchestration**
- **Airflow Webserver** : Interface web d'Airflow (port 8081)
- **Airflow Scheduler** : Planification des DAGs

---

## üìä Architecture des Composants

### **1. API FastAPI** (`src/api/`)

#### Point d'entr√©e : [`src/api/main.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/main.py)
- Importe simplement `app` depuis `api.app`

#### Application principale : [`src/api/app.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/app.py)
- **Middleware CORS** : Permet les requ√™tes cross-origin
- **Middleware Prometheus** : Enregistre les m√©triques de chaque requ√™te
- **Routers** : Inclut 4 routers pour organiser les endpoints

#### Endpoints organis√©s par router :

##### **A. Training Router** ([`src/api/endpoints/training.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/endpoints/training.py))
- `POST /training/` : D√©clenche l'entra√Ænement en arri√®re-plan
  - Appelle [`train_model_mlflow()`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/train_model_pipeline.py)
  - Utilise `BackgroundTasks` pour ne pas bloquer
- `GET /training/status` : Retourne le statut de l'entra√Ænement
  - V√©rifie `training_status` global
  - R√©cup√®re les m√©triques depuis MLflow

##### **B. Predict Router** ([`src/api/endpoints/predict.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/endpoints/predict.py))
- `POST /predict/` : G√©n√®re des recommandations
  - Charge le mod√®le depuis `models/model.pkl`
  - G√®re le **cold start** pour nouveaux utilisateurs
  - Appelle [`predict_model_pipeline.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/predict_model_pipeline.py)

##### **C. Data Router** ([`src/api/endpoints/data.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/endpoints/data.py))
- `POST /generate-ratings/` : G√©n√®re des √©valuations al√©atoires
- `GET /get-random-ratings/` : R√©cup√®re des √©valuations al√©atoires
- `GET /stats` : Statistiques sur les donn√©es

##### **D. Monitoring Router** ([`src/api/endpoints/monitoring.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/endpoints/monitoring.py))
- `GET /monitoring/drift` : D√©tecte le data drift
- `GET /monitoring/drift/evidently` : Rapport Evidently
- `POST /monitoring/drift/baseline` : Cr√©e une baseline
- `GET /monitoring/stats` : Statistiques de monitoring

#### Modules de support :

- [`database.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/database.py) : Connexion PostgreSQL
- [`schemas.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/schemas.py) : Mod√®les Pydantic
- [`cold_start.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/cold_start.py) : Gestion des nouveaux utilisateurs
- [`data_drift.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/data_drift.py) : D√©tection de drift
- [`evidently_drift.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/evidently_drift.py) : Rapports Evidently
- [`monitoring.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/monitoring.py) : M√©triques de qualit√©
- [`prometheus_metrics.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/prometheus_metrics.py) : M√©triques Prometheus

---

### **2. Pipeline d'Entra√Ænement** (`src/pipeline/`)

#### Configuration : [`config.yaml`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/config.yaml)
- Chemins des mod√®les, donn√©es, m√©triques
- Configuration MLflow
- Param√®tres du mod√®le

#### Chargement des donn√©es : [`data_loader.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/data_loader.py)
- `load_filtered_ratings()` : Charge les √©valuations depuis PostgreSQL
- Filtre les utilisateurs/films avec peu d'√©valuations

#### Entra√Ænement : [`train_model_pipeline.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/train_model_pipeline.py)

**Flux d'ex√©cution** :

1. **Connexion MLflow** : Configure le tracking URI et l'exp√©rience
2. **Chargement des donn√©es** : Appelle `load_filtered_ratings()`
3. **√âchantillonnage** : Cr√©e des √©chantillons pour la validation crois√©e
4. **Entra√Ænement de 3 mod√®les** :
   - **SVD** (Singular Value Decomposition)
   - **KNNBasic** (K-Nearest Neighbors)
   - **NormalPredictor** (baseline al√©atoire)
5. **Validation crois√©e** : 3-fold CV pour chaque mod√®le
6. **Logging MLflow** : Enregistre param√®tres et m√©triques (RMSE, MAE)
7. **S√©lection du meilleur mod√®le** : Compare les RMSE
8. **Comparaison avec mod√®le pr√©c√©dent** :
   - Recherche le meilleur run pr√©c√©dent
   - Ne remplace que si am√©lioration ou si `force=True`
9. **Entra√Ænement final** : Sur un √©chantillon plus large
10. **Sauvegarde** :
    - Fichier local : `models/model.pkl`
    - Artefact MLflow : Stock√© dans MinIO
    - Mod√®le enregistr√© : `Best_Film_Recommender`

#### Pr√©diction : [`predict_model_pipeline.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/predict_model_pipeline.py)

**Flux d'ex√©cution** :

1. **Chargement du mod√®le** : Depuis `models/model.pkl`
2. **R√©cup√©ration des films** : Depuis PostgreSQL
3. **G√©n√©ration des pr√©dictions** : Pour tous les films non vus
4. **Tri et filtrage** : Top N recommandations
5. **Sauvegarde** : Dans `predictions/predictions.csv`

---

### **3. Interface Streamlit** (`src/`)

#### Application principale : [`streamlit_app.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/streamlit_app.py)
- Page d'accueil avec statut du syst√®me
- V√©rifie la connexion API via `/health`

#### Pages : (`src/pages/`)
- **Pr√©diction** : Interface pour obtenir des recommandations
- **Entra√Ænement** : Lancer et suivre l'entra√Ænement
- **Monitoring** : Visualiser les m√©triques et le drift

#### Utilitaires : [`api_utils.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api_utils.py)
- `api_request()` : Fonction helper pour appeler l'API

---

### **4. Orchestration Airflow** (`dags/`)

#### DAG : [`training_dag.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/dags/training_dag.py)

**Configuration** :
- **Nom** : `movie_reco_training_pipeline`
- **Schedule** : `0 2 * * *` (tous les jours √† 2h du matin)
- **Tags** : `mlops`, `reco`

**T√¢ches** :
1. `check_api_health` : V√©rifie que l'API est disponible (`GET /health`)
2. `generate_new_data` : G√©n√®re de nouvelles donn√©es (`POST /generate-ratings`)
3. `trigger_training` : Appelle `POST /training/` avec `force=True`

**D√©pendances** : `check_api_health >> generate_new_data >> trigger_training`

---

## üîÑ Flux de Donn√©es Complet

### **Sc√©nario 1 : Premier d√©marrage**

```mermaid
graph TD
    A[docker compose up] --> B[PostgreSQL d√©marre]
    B --> C[init_db.sh cr√©e tables]
    C --> D[import_data.py charge CSV]
    D --> E[MinIO d√©marre]
    E --> F[MLflow d√©marre]
    F --> G[API d√©marre]
    G --> H[Streamlit d√©marre]
    H --> I[Airflow d√©marre]
```

### **Sc√©nario 2 : Entra√Ænement manuel**

```mermaid
graph TD
    A[Utilisateur clique sur Streamlit] --> B[POST /training/]
    B --> C[BackgroundTask lance run_training]
    C --> D[train_model_mlflow]
    D --> E[load_filtered_ratings depuis PostgreSQL]
    E --> F[Entra√Æne SVD, KNN, NormalPredictor]
    F --> G[Validation crois√©e 3-fold]
    G --> H[Log m√©triques dans MLflow]
    H --> I[Compare avec meilleur mod√®le pr√©c√©dent]
    I --> J{Am√©lioration?}
    J -->|Oui| K[Sauvegarde model.pkl]
    J -->|Non| L[Conserve ancien mod√®le]
    K --> M[Enregistre dans MLflow Registry]
    M --> N[Stocke artefacts dans MinIO]
```

### **Sc√©nario 3 : Pr√©diction**

```mermaid
graph TD
    A[POST /predict/ user_id=123] --> B{Utilisateur existe?}
    B -->|Non| C[cold_start.py]
    C --> D[Recommandations par popularit√© + genres]
    B -->|Oui| E[Charge model.pkl]
    E --> F[predict_model_pipeline]
    F --> G[R√©cup√®re films depuis PostgreSQL]
    G --> H[G√©n√®re pr√©dictions pour films non vus]
    H --> I[Tri par score d√©croissant]
    I --> J[Retourne top N films]
```

### **Sc√©nario 4 : Entra√Ænement automatique (Airflow)**

```mermaid
graph TD
    A[Tous les jours √† 2h] --> B[Airflow Scheduler d√©clenche DAG]
    B --> C[check_api_health v√©rifie GET /health]
    C --> D{API healthy?}
    D -->|Oui| E[trigger_training appelle POST /training/]
    D -->|Non| F[Retry apr√®s 30s]
    E --> G[M√™me flux que Sc√©nario 2]
```

---

## üìÅ Structure des Fichiers Cl√©s

### **Fichiers de configuration**

| Fichier | R√¥le |
|---------|------|
| [`docker-compose.yml`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/docker-compose.yml) | Orchestration de tous les services |
| [`src/pipeline/config.yaml`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/config.yaml) | Configuration du pipeline ML |
| [`dvc.yaml`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/dvc.yaml) | Pipeline DVC (non utilis√© en production) |
| [`requirements.txt`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/requirements.txt) | D√©pendances Python |

### **Scripts d'initialisation**

| Fichier | Ex√©cution | R√¥le |
|---------|-----------|------|
| [`src/data/sql/init_init_db.sh`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/init_init_db.sh) | Au d√©marrage | Cr√©e utilisateurs et bases de donn√©es |
| [`src/data/sql/create_table.sql`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/create_table.sql) | Apr√®s init_db | Cr√©e le sch√©ma de la base |
| [`docker/import_data/init_import_data.sh`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/docker/import_data/init_import_data.sh) | Apr√®s init_db | Lance l'import si n√©cessaire |
| [`src/data/sql/import_data.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/data/sql/import_data.py) | Si base vide | Importe les 20M d'√©valuations |

### **Code m√©tier**

| Fichier | R√¥le |
|---------|------|
| [`src/api/app.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/app.py) | Application FastAPI principale |
| [`src/pipeline/train_model_pipeline.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/train_model_pipeline.py) | Entra√Ænement avec MLflow |
| [`src/pipeline/predict_model_pipeline.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/pipeline/predict_model_pipeline.py) | G√©n√©ration de pr√©dictions |
| [`src/api/cold_start.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/src/api/cold_start.py) | Gestion nouveaux utilisateurs |
| [`dags/training_dag.py`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/dags/training_dag.py) | DAG Airflow quotidien |

---

## üîç Monitoring et Observabilit√©

### **Prometheus** ([`docker/prometheus/prometheus.yml`](file:///c:/Users/Rom/jun25_bmle_mlops_reco_films/docker/prometheus/prometheus.yml))
- Scrape l'endpoint `/metrics` de l'API toutes les 15s
- M√©triques collect√©es :
  - `api_requests_total` : Nombre de requ√™tes par endpoint
  - `api_request_duration_seconds` : Latence des requ√™tes
  - `training_runs_total` : Nombre d'entra√Ænements
  - M√©triques custom de qualit√© des recommandations

### **Grafana**
- Dashboards pr√©-configur√©s dans `docker/grafana/`
- Visualise les m√©triques Prometheus
- Acc√®s : http://localhost:3001 (admin/admin)

### **Evidently**
- G√©n√®re des rapports HTML de data drift
- Compare distribution actuelle vs baseline
- D√©tecte les changements dans les features

---

## üéØ Points d'Entr√©e Utilisateur

### **1. Via Streamlit** (Recommand√© pour utilisateurs)
- **URL** : http://localhost:8501
- **Fonctionnalit√©s** :
  - Obtenir des recommandations pour un utilisateur
  - Lancer un entra√Ænement
  - Visualiser les m√©triques de monitoring

### **2. Via API** (Pour d√©veloppeurs/int√©grations)
- **URL** : http://localhost:8080
- **Documentation** : http://localhost:8080/docs
- **Exemples** :
  ```bash
  # Obtenir des recommandations
  curl -X POST http://localhost:8080/predict/ \
    -H "Content-Type: application/json" \
    -d '{"user_id": 1, "n_recommendations": 10}'
  
  # Lancer un entra√Ænement
  curl -X POST http://localhost:8080/training/ \
    -H "Content-Type: application/json" \
    -d '{"force": true}'
  ```

### **3. Via Airflow** (Automatisation)
- **URL** : http://localhost:8081
- **Credentials** : admin/admin
- **DAG** : `movie_reco_training_pipeline`
- **Schedule** : Quotidien √† 2h du matin

### **4. Via MLflow** (Suivi des exp√©riences)
- **URL** : http://localhost:5000
- **Fonctionnalit√©s** :
  - Comparer les runs d'entra√Ænement
  - Visualiser les m√©triques (RMSE, MAE)
  - T√©l√©charger les mod√®les

---

## üîê Variables d'Environnement Importantes

### **API**
- `MLFLOW_TRACKING_URI=http://mlflow:5000`
- `MLFLOW_S3_ENDPOINT_URL=http://minio:9000`
- `DB_HOST=db`, `DB_NAME=reco_films`
- `AWS_ACCESS_KEY_ID=minioadmin`

### **MLflow**
- `AWS_ACCESS_KEY_ID=minioadmin`
- `AWS_SECRET_ACCESS_KEY=minioadmin123`
- `MLFLOW_S3_ENDPOINT_URL=http://minio:9000`

### **Airflow**
- `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow`
- `AIRFLOW_CONN_API_CONNECTION=http://api:8000`

---

## üìù R√©sum√© du Flux de Vie d'une Recommandation

1. **Donn√©es** : CSV ‚Üí PostgreSQL (via `import_data.py`)
2. **Entra√Ænement** : PostgreSQL ‚Üí `train_model_pipeline.py` ‚Üí MLflow ‚Üí MinIO
3. **Mod√®le** : MLflow ‚Üí `models/model.pkl` (local)
4. **Pr√©diction** : `model.pkl` + PostgreSQL ‚Üí `predict_model_pipeline.py` ‚Üí API
5. **Interface** : Streamlit ‚Üí API ‚Üí Utilisateur
6. **Monitoring** : API ‚Üí Prometheus ‚Üí Grafana
7. **Orchestration** : Airflow ‚Üí API ‚Üí Entra√Ænement quotidien
